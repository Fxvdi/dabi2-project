{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wetterdaten data cleaning & filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bereinigen und formatieren von Wetterdaten\n",
    "\n",
    "__Ziel__: Mit einer Schleife auf alle Ordner/csv-Dateien durchführen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240623_141902'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Aktuelles Datum und Uhrzeit im Format jjjjmmtt_hhmmss\n",
    "current_datetime = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "current_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diese Zelle nicht mehr ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Definiere den Ordnerpfad\n",
    "# ordnerpfad = '../Data_Lake/Wetterdaten'\n",
    "\n",
    "# # Durchlaufe jeden Ordner im Hauptordner\n",
    "# for ordnername in os.listdir(ordnerpfad):\n",
    "#     # Überprüfe, ob es sich um einen Ordner handelt\n",
    "#     if os.path.isdir(os.path.join(ordnerpfad, ordnername)):\n",
    "#         # Durchlaufe jede Datei im Unterordner\n",
    "#         unterordner_pfad = os.path.join(ordnerpfad, ordnername)\n",
    "#         for dateiname in os.listdir(unterordner_pfad):\n",
    "#             # Überprüfe, ob die Datei eine .txt-Datei ist\n",
    "#             if dateiname.endswith('.txt'):\n",
    "#                 # Baue den alten und neuen Dateinamen\n",
    "#                 alter_pfad = os.path.join(unterordner_pfad, dateiname)\n",
    "#                 neuer_name = os.path.splitext(dateiname)[0] + '.csv'\n",
    "#                 neuer_pfad = os.path.join(unterordner_pfad, neuer_name)\n",
    "                \n",
    "#                 # Umbenenne die Datei\n",
    "#                 os.rename(alter_pfad, neuer_pfad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ab hier wieder normal durchlaufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather1 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_00377_19470101_20231231_hist/produkt_klima_tag_19470101_20231231_00377.csv\", delimiter=\";\")\n",
    "df_weather2 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_00433_19480101_20231231_hist/produkt_klima_tag_19480101_20231231_00433.csv\", delimiter=\";\")\n",
    "df_weather3 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_00555_19400101_20231231_hist/produkt_klima_tag_19400101_20231231_00555.csv\", delimiter=\";\")\n",
    "df_weather4 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_00850_19470801_20231231_hist/produkt_klima_tag_19740801_20231231_00850.csv\", delimiter=\";\")\n",
    "df_weather5 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_00880_18870101_20231231_hist/produkt_klima_tag_18870101_20231231_00880.csv\", delimiter=\";\")\n",
    "df_weather6 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_01443_18740101_20221231_hist/produkt_klima_tag_18740101_20221231_01443.csv\", delimiter=\";\")\n",
    "df_weather7 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_01757_18980301_20231231_hist/produkt_klima_tag_18980301_20231231_01757.csv\", delimiter=\";\")\n",
    "df_weather8 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_01975_19360101_20231231_hist/produkt_klima_tag_19360101_20231231_01975.csv\", delimiter=\";\")\n",
    "df_weather9 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_03631_18580301_20231231_hist/produkt_klima_tag_18580301_20231231_03631.csv\", delimiter=\";\")\n",
    "df_weather10 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_03927_19580101_20231231_hist/produkt_klima_tag_19580101_20231231_03927.csv\", delimiter=\";\")\n",
    "df_weather11 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_03939_19500101_20231231_hist/produkt_klima_tag_19500101_20231231_03939.csv\", delimiter=\";\")\n",
    "df_weather12 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_04763_19610101_20231231_hist/produkt_klima_tag_19610101_20231231_04763.csv\", delimiter=\";\")\n",
    "df_weather13 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_05705_19470101_20231231_hist/produkt_klima_tag_19470101_20231231_05705.csv\", delimiter=\";\")\n",
    "df_weather14 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_05717_19370101_20231231_hist/produkt_klima_tag_19370101_20231231_05717.csv\", delimiter=\";\")\n",
    "df_weather15 = pd.read_csv(\"../Data_Lake/Wetterdaten/tageswerte_KL_05792_19000801_20231231_hist/produkt_klima_tag_19000801_20231231_05792.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [df_weather1, df_weather2, df_weather3, df_weather4, df_weather5, df_weather6, df_weather7, df_weather8, df_weather9, df_weather10, df_weather11, df_weather12, df_weather13, df_weather14, df_weather15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### löschen von Spalten\n",
    "__Spalten die nur das Qualitätsbyte -999 enthalten sollen gelöscht werden__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # 1. Leerzeichen in den Spaltennamen entfernen\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "    # 2. Über alle Spalten mit unique() prüfen und ggf. Werte ändern\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        if len(unique_values) == 1:\n",
    "            single_value = unique_values[0]\n",
    "            if single_value == -999 or single_value == \"eor\":\n",
    "                df[column] = np.nan\n",
    "\n",
    "    # 3. Alle Spalten nach -999 durchsuchen und zu NaN ändern\n",
    "    df.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "    # 4. Spalte \"MESS_DATUM\" in Datetime umwandeln\n",
    "    if 'MESS_DATUM' in df.columns:\n",
    "        df['MESS_DATUM'] = pd.to_datetime(df['MESS_DATUM'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_dataframes(dataframes, file_paths):\n",
    "    for df, path in zip(dataframes, file_paths):\n",
    "        df.to_csv(path, index=False)\n",
    "\n",
    "# Schleife durch die Liste von DataFrames und die Funktionen anwenden\n",
    "cleaned_dataframes = [clean_dataframe(df) for df in list_of_dfs]\n",
    "# Speichern von in Historie\n",
    "file_paths = [\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19470101_20231231_00377-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19480101_20231231_00433-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19400101_20231231_00555-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19740801_20231231_00850-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_18870101_20231231_00880-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_18740101_20221231_01443-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_18980301_20231231_01757-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19360101_20231231_01975-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_18580301_20231231_03631-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19580101_20231231_03927-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19500101_20231231_03939-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19610101_20231231_04763-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19470101_20231231_05705-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19370101_20231231_05717-{current_datetime}.csv\",\n",
    "    f\"../Data_Lake/Historisierung/Wetterdaten/Tagesbasis/produkt_klima_tag_19000801_20231231_05792-{current_datetime}.csv\",\n",
    "]\n",
    "# Bereinigte DataFrames speichern\n",
    "save_dataframes(cleaned_dataframes, file_paths)\n",
    "# Optional: Wenn Sie die DataFrames wieder in einer Liste speichern möchten\n",
    "# dataframes = cleaned_dataframes\n",
    "\n",
    "# for df in cleaned_dataframes:\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eor'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_weather[\"STATIONS_ID\"].unique()\n",
    "#df_weather[\"MESS_DATUM\"].unique()\n",
    "#df_weather[\"QN_3\"].unique()\n",
    "#df_weather[\"  FX\"].unique()\n",
    "#df_weather[\"  FM\"].unique()\n",
    "#df_weather[\"QN_4\"].unique()\n",
    "#df_weather1[\" RSK\"].unique()\n",
    "#df_weather1[\"RSKF\"].unique()\n",
    "#df_weather[\" SDK\"].unique()\n",
    "#df_weather[\"SHK_TAG\"].unique()\n",
    "#df_weather[\"  NM\"].unique()\n",
    "#df_weather[\" VPM\"].unique()\n",
    "#df_weather[\"  PM\"].unique()\n",
    "#df_weather[\" TMK\"].unique()\n",
    "#df_weather[\" UPM\"].unique()\n",
    "#df_weather[\" TXK\"].unique()\n",
    "#df_weather[\" TNK\"].unique()\n",
    "#df_weather1[\" TGK\"].unique()\n",
    "#df_weather1[\"eor\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Je Nach Untersuchungsart nochmal aufteilen)\n",
    "__zum Beispiel \"Wind\", \"Niederschlag\", \"Temperatur\", ...__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Qualitätsniveaus wurden rausgeworfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
